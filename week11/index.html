<!DOCTYPE html>
<html>
  <head>
    <title>Digital Humanities</title>
    <meta charset="utf-8">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="pygments.css" type="text/css" />
    <style>
      pre { padding: 7px;}
      th {color: white; background-color: black; padding-top: 7px; padding-bottom: 7px;}
      td {padding: 3px; }
      table { width: 100%; border-collapse: collapse;}
      td, th {border: 1px solid black; font-size: 95%; text-align: center;
      }
      body {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        color: rgba(34,34,34,.77);
      }
      .remark-slide-content h1 {
          font-size: 45px;
      }
      h1 {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        font-weight: normal;
        margin-top: 5px;
        margin-bottom: 5px;
        color: black;
        font-variant: small-caps;
      }
      h2 {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        font-weight: normal;
        color: black;
        margin-top: 5px;
        margin-bottom: 5px;
      }
      h3, h4 {
        font-size: 115%;
        color: rgba(34,34,34,.77);
        font-weight: normal;
        margin-top: 5px;
        margin-bottom: 5px;
      }
      p {
        margin-top: 1px;
        margin-bottom: 1px;
      }
      .youtube {
        width: 100%;
        height: 45vh;
      }
      .middle {
        
        background-image: linear-gradient(#E1E1E1, #68AA5E 45%);
      }
    </style>
  </head>
  <body>
    <textarea id="source">


class: middle

# Text Analysis Methods Workshop 11: 

### TF-IDF and Clustering

<hr>
Matthew J. Lavin

Clinical Assistant Professor of English and Director of Digital Media Lab

University of Pittsburgh

Fall 2018

---
class: middle

# What is TF-IDF?

<hr>
#### TF-IDF stands for Term Frequency - Inverse Document Frequency. Instead of representing a term in a document by its raw frequency (number of occurrences) or its relative frequency (term count divided by document length), each term is weighted by dividing the term frequency by the (1) frequency of the word in the corpus, or (2) the number of documents in the corpus that contain the word. 
<hr>

---
class: middle

# How Does the Math Work?

<hr>

#### The formula is: tf-idf(d, t) = tf(t) * idf(d, t) 
#### tf(t) is the term frequency of a term, either a raw count or a normalized value
#### idf(d, t)  is log [ n / df(d, t) ] + 1 where _log_ equals the natural logarithm of the derived value
#### n is the total number of documents
#### df is the number of documents containing the term (t)

<hr>


---
class: middle

# An Example: One Obituary among Many

<div>
<table border="1" class="dataframe">
<thead>
  <tr style="text-align: right;">
    <th title="Term">Term</th>
    <th title="Count">Count</th>
    <th title="DF">DF</th>
    <th title="Smoothed-IDF">Smoothed-IDF</th>
    <th title="TF-IDF">TF-IDF</th>
    
    </tr>
</thead>
<tbody>
<tr>
<td>afternoon</td>
<td>1</td>
<td>66</td>
<td>2.70066923</td>
<td>2.70066923</td>

</tr>
<tr>
<td>against</td>
<td>1</td>
<td>189</td>
<td>1.65833778</td>
<td>1.65833778</td>

</tr>
<tr>
<td>age</td>
<td>1</td>
<td>224</td>
<td>1.48926145</td>
<td>1.48926145</td>

</tr>
<tr>
<td>ago</td>
<td>1</td>
<td>161</td>
<td>1.81776551</td>
<td>1.81776551</td>

</tr>
<tr>
<td>air</td>
<td>1</td>
<td>80</td>
<td>2.51091269</td>
<td>2.51091269</td>

</tr>
<tr>
<td>all</td>
<td>1</td>
<td>310</td>
<td>1.16556894</td>
<td>1.16556894</td>

</tr>
<tr>
<td>american</td>
<td>1</td>
<td>277</td>
<td>1.27774073</td>
<td>1.27774073</td>

</tr>
<tr>
<td>an</td>
<td>1</td>
<td>352</td>
<td>1.03889379</td>
<td>1.03889379</td>

</tr>
<tr>
<td>and</td>
<td>13</td>
<td>364</td>
<td>1.00546449</td>
<td>13.07103843</td>

</tr>
<tr>
<td>around</td>
<td>2</td>
<td>149</td>
<td>1.89472655</td>
<td>3.78945311</td>
</tr>

<tr>
<td>as</td>
<td>2</td>
<td>357</td>
<td>1.02482886</td>
<td>2.04965772</td>
</tr>

<tr>
<td>ascension</td>
<td>1</td>
<td>6</td>
<td>4.95945170</td>
<td>4.95945170</td>
</tr>
</tbody>
</table>
</div>



Download a complete excel file on [Github](https://github.com/dh-fall-2018/tfidf-explore/blob/master/bly_tfidf_all.xlsx?raw=true)

---
class: middle

# In Python 

<hr>
<div class="highlight"><pre><span></span><span class="c1"># all_docs can be any list of strings,</span>
<span class="c1"># each item representing a document </span>
<span class="n">a</span> <span class="o">=</span> <span class="s1">&#39;The once ruddy face was puffy and pale&#39;</span>
<span class="n">b</span> <span class="o">=</span> <span class="s1">&#39;The gray hair was straight and thin&#39;</span>
<span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;His dark brown eyes looked fixed, and he seemed \</span>
<span class="s1">to be daydreaming&#39;</span>
<span class="n">d</span> <span class="o">=</span> <span class="s1">&#39;his figure was trim and erect&#39;</span>

<span class="n">all_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span><span class="p">]</span>
</pre></div>
<hr>

---
class: middle

# In Python 

<hr>

<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="c1"># TfidfVectorizer is a class, so I instantiate it </span>
<span class="c1"># with specific pararmeters as &#39;vectorizer&#39;</span>
<span class="c1"># I then run the object&#39;s fit_transform() </span>
<span class="c1"># method on my list of strings (all_docs)</span>
<span class="c1"># The stored variable X is output of the </span>
<span class="c1"># fit_transform() method </span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=.</span><span class="mi">65</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
  <span class="n">stop_words</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">use_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">all_docs</span><span class="p">)</span>
</pre></div>

<hr>

---
class: middle

# In Python 

<hr>
<div class="highlight"><pre><span></span><span class="c1"># The fit_transform() method converts the list of </span>
<span class="c1"># strings to a sparse matrix of TF-IDF values</span>
<span class="c1"># The toarray method converts a numpy array, which </span>
<span class="c1"># makes it easier to indpect every values including the zeros </span>
<span class="n">myarray</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="c1"># prints the first row of results</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<hr>

---
class: middle

# In Python 

<hr>
<div class="highlight"><pre><span></span><span class="c1"># You can merge the results for each doc</span>
<span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(),</span> <span class="n">myarray</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
<hr>

---
class: middle

# Exploratory Applications

<hr>
#### TF-IDF is often used to simply produce re-ranked term lists for a large group of documents 
<hr>
See https://github.com/dh-fall-2018/tfidf-explore/blob/master/ExploreFiles.ipynb

---
class: middle

# Using It As a Preprocessing Step

<hr>
- #### Many machine learning algorithms begin by vectorizing text and running TF-IDF
- #### For example, I could next run k-means clustering and split the obits into three groups to see what lands where 

<hr>

---
class: middle

# Using it To Make Feature Lists

<hr>
- #### To derive a feature set, I might run TF-IDF on a group of documents about a subject
- #### For example, obits in one pile, non-obits in another
- #### Then I can take the top N TF-IDF terms (say 50) and see which novels use those words the most 

<hr>

---
class: middle

# Clustering

<hr>
- #### Clustering can be supervised or unsupervised
- #### Uses either flat or non-flat geometry to measure vectors' relationships with one another
- #### See https://scikit-learn.org/stable/modules/clustering.html for explanations of many algorithms

<hr>

---
class: middle

# K-means Clustering

<hr>
- #### User supplies a number of clusters
- #### The model tries various groupings, calculates a "centroid" of the data (a multidimensional center) ands then measures the mean distance from the centroid
- #### More coherent groups have lower "inertia" 

<hr>

See https://github.com/dh-fall-2018/tfidf-explore/blob/master/ExploreFiles.ipynb

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
