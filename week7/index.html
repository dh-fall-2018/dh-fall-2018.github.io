<!DOCTYPE html>
<html>
  <head>
    <title>Digital Humanities</title>
    <meta charset="utf-8">
    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="pygments.css" type="text/css" />
    <style>

      th {color: white; background-color: black; padding-top: 7px; padding-bottom: 7px;}
      td {padding: 3px; }
      table { width: 100%; border-collapse: collapse;}
      td, th {border: 1px solid black; font-size: 95%; text-align: center;
      }
      body {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        color: rgba(34,34,34,.77);
      }
      .remark-slide-content h1 {
          font-size: 45px;
      }
      h1 {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        font-weight: normal;
        margin-top: 5px;
        margin-bottom: 5px;
        color: black;
        font-variant: small-caps;
      }
      h2 {
        font-family: 'Helvetica Neue', 'Arial', 'sans-serif';
        font-weight: normal;
        color: black;
        margin-top: 5px;
        margin-bottom: 5px;
      }
      h3, h4 {
        font-size: 115%;
        color: rgba(34,34,34,.77);
        font-weight: normal;
        margin-top: 5px;
        margin-bottom: 5px;
      }
      p {
        margin-top: 1px;
        margin-bottom: 1px;
      }
      .youtube {
        width: 100%;
        height: 45vh;
      }
      .middle {
        
        background-image: linear-gradient(#E1E1E1, #47807A 45%);
      }
    </style>
  </head>
  <body>
    <textarea id="source">


class: middle

# Text Analysis Methods Workshop 7: 

### Dictionaries and Lexicons

<hr>
Matthew J. Lavin

Clinical Assistant Professor of English and Director of Digital Media Lab

University of Pittsburgh

Fall 2018

---
class: middle

# Reminder: Corpus vs. Lexicon or Dictionary

<hr>
#### A corpus collects  "real world language" and is often annotated. Many corpora are large and make a claim of representativeness. (Like the "Corpus of Contemporary American English")
<hr>
---
class: middle

# Reminder: Corpus vs. Lexicon or Dictionary

<hr>
#### A lexicon or dictionary is a list of words or phrases that match some criteria, and/or a wordlist with information about those words. For example, SocialSent includes .tsv files, by decade, covering the years 1850-2000. 
<hr>
#### Each .tsv has the format, <word>\t<mean_sentiment>\t<std_sentiment>\n where "mean_sentiment is the averaged inferred sentiment across bootstrap-sampled SentProp runs and std_sentiment is the standard deviation of these samples."
<hr>
---
class: middle

# Helpful Resources to Know about
<hr>
- #### The CMU Pronouncing Dictionary 
- #### WordNet, VerbNet
- #### Wordlist corpora (stopwords, names)
- #### LIWC (costs $)
- #### SensEval
- #### SocialSent
- #### The North Atlantic Population Project (NAPP)
- #### And many more!

---
class: middle

# Common Formats

<hr>
### As with corpora, you are most likely to see .txt, .csv, .xml, and .json files. 
<hr>

---
class: middle

# Importing in Python

<hr>
### Working with a lexicon or dictionary in Python almost always involves loading the structured data as a _list_, a _dictionary_, or a pandas _dataframe_ 
<hr>
---
class: middle

# An Activity

<hr>
### Let's break into groups of 2-3 students and try to load SocialSent adjective data and use it to generate a 'positivity score' for some texts.
<hr>
---
class: middle

# Downloading the Repo 

### I've created a starter repo with the SocialSent adjective data and a set of texts to analyze. Clone it here: https://github.com/dh-fall-2018/social-sent-activity
<hr>
#### The repository contains approximately 6400 opo-eds from _The New York Times_, all published between January and September 2018. There's a metadata.csv file with columns representing an <id>,<url>,<word_count>,<snippet>,<source>,< byline>,<byline_parsed>,<pub_date>, and <inferred_gender>. With the exception of <byline_parsed> and <inferred_gender>, the fields are all taken from _The New York Times_ Article API. <byline_parsed> attempts to isolate the author's name, and <inferred_gender> assigns a gender label using the R package 'gender', which returns a gender probability given a name input and a date. The inference is made by looking up census data. 
<hr>
---
class: middle

# Breaking down the problem 

<hr>
- #### Loading a decade file from SocialSent into Python (as a dictionary)
- #### Loading and tokenizing fifty texts (using spacy?)
- #### Looping each text and checking each token against our dictionary
- #### DEsigning the "positivity score"
- #### Saving an aggregated score for each file

<hr>
---
class: middle

# Sharing Your Process

<hr>
- #### How did it go? Did you complete the challenge?
- #### What strategies were successful? Did you consult code from previous weeks' workshops? 
- #### What did effective communication and teamwork feel like for this activity? 
<hr>


    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
